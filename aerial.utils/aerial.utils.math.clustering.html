<!DOCTYPE html>
<html><head><meta charset="UTF-8"><link href="css/default.css" rel="stylesheet" type="text/css"><script src="js/jquery.min.js" type="text/javascript"></script><script src="js/page_effects.js" type="text/javascript"></script><title>aerial.utils.math.clustering documentation</title></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Aerial.utils</span> <span class="project-version">1.2.0</span></span></a></h1></div><div class="sidebar primary"><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Topics</span></h3><ul><li class="depth-1 "><a href="intro.html"><div class="inner"><span>Introduction to utils</span></div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>aerial</span></div></div></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>utils</span></div></div></li><li class="depth-3 branch"><a href="aerial.utils.coll.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>coll</span></div></a></li><li class="depth-3"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ds</span></div></div></li><li class="depth-4 branch"><a href="aerial.utils.ds.bktrees.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>bktrees</span></div></a></li><li class="depth-4 branch"><a href="aerial.utils.ds.graphs.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>graphs</span></div></a></li><li class="depth-4"><a href="aerial.utils.ds.trees.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>trees</span></div></a></li><li class="depth-3 branch"><a href="aerial.utils.io.html"><div class="inner"><span class="tree" style="top: -114px;"><span class="top" style="height: 123px;"></span><span class="bottom"></span></span><span>io</span></div></a></li><li class="depth-3"><a href="aerial.utils.math.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>math</span></div></a></li><li class="depth-4 branch current"><a href="aerial.utils.math.clustering.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clustering</span></div></a></li><li class="depth-4 branch"><a href="aerial.utils.math.combinatorics.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>combinatorics</span></div></a></li><li class="depth-4 branch"><a href="aerial.utils.math.infoth.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>infoth</span></div></a></li><li class="depth-4 branch"><a href="aerial.utils.math.probs-stats.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>probs-stats</span></div></a></li><li class="depth-4"><a href="aerial.utils.math.scores.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>scores</span></div></a></li><li class="depth-3 branch"><a href="aerial.utils.misc.html"><div class="inner"><span class="tree" style="top: -176px;"><span class="top" style="height: 185px;"></span><span class="bottom"></span></span><span>misc</span></div></a></li><li class="depth-3"><a href="aerial.utils.string.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>string</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-center-dist-expect"><div class="inner"><span>center-dist-expect</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-center-distances"><div class="inner"><span>center-distances</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-centers"><div class="inner"><span>centers</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-cluster-distances"><div class="inner"><span>cluster-distances</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-cluster-stdev"><div class="inner"><span>cluster-stdev</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-clusters"><div class="inner"><span>clusters</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-davies-bouldin-index"><div class="inner"><span>davies-bouldin-index</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-DBI-Rij"><div class="inner"><span>DBI-Rij</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-DBI-Si"><div class="inner"><span>DBI-Si</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-density"><div class="inner"><span>density</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-dist-matrix"><div class="inner"><span>dist-matrix</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-edist"><div class="inner"><span>edist</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-extreme-pd"><div class="inner"><span>extreme-pd</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-farthest"><div class="inner"><span>farthest</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-farthest-pd"><div class="inner"><span>farthest-pd</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-find-clusters"><div class="inner"><span>find-clusters</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-intercluster-density"><div class="inner"><span>intercluster-density</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-intra-dist-expect"><div class="inner"><span>intra-dist-expect</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-intra-distances"><div class="inner"><span>intra-distances</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-ith-sum-sqr-err"><div class="inner"><span>ith-sum-sqr-err</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-kmeans"><div class="inner"><span>kmeans</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-kmeans.2B.2B"><div class="inner"><span>kmeans++</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-knn"><div class="inner"><span>knn</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-knn-graph"><div class="inner"><span>knn-graph</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-krnn-clust"><div class="inner"><span>krnn-clust</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-krnn-graph"><div class="inner"><span>krnn-graph</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-loyd-step"><div class="inner"><span>loyd-step</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-nearest"><div class="inner"><span>nearest</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-nearest-pd"><div class="inner"><span>nearest-pd</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-refoldin-outliers"><div class="inner"><span>refoldin-outliers</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-S-Dbw-index"><div class="inner"><span>S-Dbw-index</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-scatt"><div class="inner"><span>scatt</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-split-krnn"><div class="inner"><span>split-krnn</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-split-worst-cluster"><div class="inner"><span>split-worst-cluster</span></div></a></li><li class="depth-1"><a href="aerial.utils.math.clustering.html#var-sum-sqr-err"><div class="inner"><span>sum-sqr-err</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">aerial.utils.math.clustering</h1><div class="doc"><pre class="plaintext">Various data clustering algorithms, techniques, functions.
Generally applicable, but typically used for sequence clustering of
various sorts.</pre></div><div class="public anchor" id="var-center-dist-expect"><h3>center-dist-expect</h3><div class="usage"><code>(center-dist-expect distfn clustering &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">The expectation of all center distances of clusters in CLUSTERING.
Distances are computed by DISTFN.  Expectation is computed by AVGFN
which defaults to the mean.
</pre></div></div><div class="public anchor" id="var-center-distances"><h3>center-distances</h3><div class="usage"><code>(center-distances distfn clustering)</code></div><div class="doc"><pre class="plaintext">Pairwise distances of centers of clusters Ci in CLUSTERING by means
of distance function DISTFN.
</pre></div></div><div class="public anchor" id="var-centers"><h3>centers</h3><div class="usage"><code>(centers avgfn clusters)</code></div><div class="doc"><pre class="plaintext">Compute a new set of centers from CLUSTERS using AVGFN as a &apos;mean&apos;
for the points in each cluster Ci of clusters.  Returns an &apos;eager&apos;
seq of these new centers.
</pre></div></div><div class="public anchor" id="var-cluster-distances"><h3>cluster-distances</h3><div class="usage"><code>(cluster-distances distfn clusters)</code></div><div class="doc"><pre class="plaintext">Given a clustering CLUSTERS and its distance function DISTFN,
returns a set of scores/measures of the quality of the clustering,
a map with keys [:global, :each, :inter-m-xs, inter-xs, ...].
Where,

* global gives a global intra cluster cohesion, uses SSE

* each gives intra cluster cohesion for each cluster, uses SSE

* inter a global inter cluster cohesion (sum of sqrs of center
  distances)

* inter-ms gives pairwise inter cluster cohesion (center distances)

* inter-m-xs gives pairwise inter cluster cohesion by min distances
  over points xis in Ci to center mj of Cj and vice versa.

* inter-xs gives pairwise inter cluster cohesion by min distance
  over all [xi, xj] pairs, xi in Ci, xj in Cj
</pre></div></div><div class="public anchor" id="var-cluster-stdev"><h3>cluster-stdev</h3><div class="usage"><code>(cluster-stdev distfn avgfn clustering)</code></div><div class="doc"><pre class="plaintext">Compute the average standard deviation of the spread of clusters in
CLUSTERING, the result of a (clusters ...) call.  This is not as
obvious as it may seem, and is basically (avg-std-deviation
clustering) except we cheat a bit as we already have the
means (centers).
</pre></div></div><div class="public anchor" id="var-clusters"><h3>clusters</h3><div class="usage"><code>(clusters distfn coll centers)</code></div><div class="doc"><pre class="plaintext">Form and return a set of clusters.  Each cluster is the set of
points from COLL closest to a point ci in CENTERS as determined by
distance function distfn (see nearest).  Result is a map with keys
ci and values the cluster points for ci.
</pre></div></div><div class="public anchor" id="var-davies-bouldin-index"><h3>davies-bouldin-index</h3><div class="usage"><code>(davies-bouldin-index distfn clustering &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">Computes the Davies Bouldin Index of cluster validity.  This is a
cluster validity measure which is the average of the maximal Rij
over all not equal pairwise clusters (see DBI-Rij).
</pre></div></div><div class="public anchor" id="var-DBI-Rij"><h3>DBI-Rij</h3><div class="usage"><code>(DBI-Rij distfn clustering &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">Rij is a similarity measure between two clusters of a clustering
based on DBI-Si compactness and center point distance dij.  The
important aspects are that it is postive definite and symmetric.
Additionally, &apos;triangle like&apos; aspects hold:

* if Sj &gt; Sk and dij = dik, then Rij &gt; Rik

* if Sj = Sk and dij &lt; dik, then Rij &gt; Rik

Rij = (/ (+ Si Sj) (distfn ci cj))

Returns the collection of Rij for all pairwise clusters of
clustering as a map indexed by i in (range n), n = (count
clusterings).  The value of an entry is the n-1 set of Ri,i/=j for
cluster Ci.  Note since Rij=Rji there are duplicate values across
the entries, but they are computed only once.
</pre></div></div><div class="public anchor" id="var-DBI-Si"><h3>DBI-Si</h3><div class="usage"><code>(DBI-Si distfn cluster &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">The Davies Bouldin Index of the compactness (aka &apos;scatter&apos; or Si)
of cluster CLUSTER.

Si is the expectation of pairwise distances of points in CLUSTER
with its center ci.  Distances are given by DISTFN. The expectation
is AVGFN of these distances.  AVGFN defaults to mean:

Si = (avgnf (sum (fn[xj] (distfn ci xj)) (val cluster)))

CLUSTER must be an element of a result of (clusters ...), i.e., a
map entry with center key and points val.
</pre></div></div><div class="public anchor" id="var-density"><h3>density</h3><div class="usage"><code>(density distfn stdev u coll)</code></div><div class="doc"><pre class="plaintext">Computes the &apos;density&apos; of points in COLL relative to u (typically a
&apos;center&apos; or &apos;mid point&apos; of some sort) as determined by counts
within 1 STDEV of u.  Distances are given by distance function
DISTFN.
</pre></div></div><div class="public anchor" id="var-dist-matrix"><h3>dist-matrix</h3><div class="usage"><code>(dist-matrix distfn coll &amp; {:keys [sym keyfn], :or {sym true, keyfn identity}})</code></div><div class="doc"><pre class="plaintext">Computes and returns the pairwise distance matrix for items in
COLL.  The distances between items is given by distfn.  SYM
indicates that distfn is symmetric (default) and keyfn returns a
key suitable for map entries for an item and defaults to identity.
The idea behind keyfn is that some items may be large or otherwise
complicated and thus expensive to compare but a unique key may be
generated for them beforehand.  A typical scenario would be to
&apos;Goedel number&apos; them.

Returns {[k v] | k=[(kefn i) (kefn j)] v =(distfn i j)}

Uses reducers and vfold to parallelize computation with auto
computed queue granularity (see vfold)
</pre></div></div><div class="public anchor" id="var-edist"><h3>edist</h3><div class="usage"><code>(edist x y)</code></div><div class="doc"><pre class="plaintext">Simple Euclidean distance between points x and y.  x and y are
points from the same dimensional space (1-d, 2-d, 3-d, ... n-d)
</pre></div></div><div class="public anchor" id="var-extreme-pd"><h3>extreme-pd</h3><div class="usage"><code>(extreme-pd x distfn comp coll)</code></div><div class="doc"><pre class="plaintext">For point X, compute its &apos;extreme&apos; point and its corresponding
distance from all the points in COLL.  The &apos;extremeness&apos; is
determined by COMP a comparison predicate.  For example, comp = &lt;
indicates &apos;nearest&apos;.

DISTFN is the distance function used to compute the distances of x
from any p in coll.

If coll is a map, uses (vals coll) for the candidate collection of
points.
</pre></div></div><div class="public anchor" id="var-farthest"><h3>farthest</h3><div class="usage"><code>(farthest x distfn coll)</code></div><div class="doc"><pre class="plaintext">Return the farthest point p in coll to x.  Distance is given by
distfn.  If coll is a map uses (vals coll).
</pre></div></div><div class="public anchor" id="var-farthest-pd"><h3>farthest-pd</h3><div class="usage"><code>(farthest-pd x distfn coll)</code></div><div class="doc"><pre class="plaintext">Return the farthest point p in coll to x along with its distance.
Distance is given by distfn.  If coll is a map uses (vals coll).
Returns [p,d], where p is the farthest point and d its distance.
</pre></div></div><div class="public anchor" id="var-find-clusters"><h3>find-clusters</h3><h4 class="type">multimethod</h4><div class="usage"><code>(find-clusters coll &amp; {:keys [distfn avgfn algo vindex], :or {algo kmeans++, vindex S-Dbw-index, distfn edist, avgfn mean}})</code><code>(find-clusters _ coll &amp; {:keys [distfn avgfn algo vindex], :or {algo kmeans++, vindex S-Dbw-index, distfn edist, avgfn mean}})</code></div><div class="doc"><pre class="plaintext">Computes the &apos;best&apos; clustering of the data in collection COLL whose
distances are given by DISTFN and means by AVGFN, as produced by
ALGO and measured by VINDEX.  ALGO is the clustering algorithm,
defaults to kmeans++, and VINDEX is the validity index measure,
defaults to S-Dbw-index.

&apos;Best&apos;, here is as determined by vindex.  If the data has
convex (natural/true) clusters, and is not skewed, the default
kmeans++ with S-Dbw-index will return the optimal
clustering (indeed, it will be or be extremely close to the
natural/true clustering).

If the data are not convex, kmeans++ is invalid (can only find
convex clusters...).  If the data is heavily skewed, kmeans will
not find the optimal (true) clusters (as it always tends to find
&apos;equal area&apos; clusters.
</pre></div></div><div class="public anchor" id="var-intercluster-density"><h3>intercluster-density</h3><div class="usage"><code>(intercluster-density distfn avgfn clustering &amp; {:keys [stdev]})</code></div><div class="doc"><pre class="plaintext">Compute the inter cluster point density.  This is the density
between clusters as determined by point counts 1 cluster-stdev from
midpoints between cluster centers.

Note: if (= 1 (count clustering)), simply returns the density of
the single cluster.

Returns floating point density score of separation - the smaller
the better.
</pre></div></div><div class="public anchor" id="var-intra-dist-expect"><h3>intra-dist-expect</h3><div class="usage"><code>(intra-dist-expect distfn cluster &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">The expectation of all pairwise point distances in cluster CLUSTER.
Distances are computed by DISTFN and expectation by AVGFN, which
defaults to mean. CLUSTER is either an element of a result
of (clusters ...), i.e., a map entry with center key and points
val, or the point collection of such cluster.
</pre></div></div><div class="public anchor" id="var-intra-distances"><h3>intra-distances</h3><div class="usage"><code>(intra-distances distfn cluster)</code></div><div class="doc"><pre class="plaintext">Pairwise distances of points in a cluster CLUSTER as given by
DISTFN.  CLUSTER is either an element of a result of (clusters
...), i.e., a map entry with center key and points val, or the
point collection of such cluster.
</pre></div></div><div class="public anchor" id="var-ith-sum-sqr-err"><h3>ith-sum-sqr-err</h3><div class="usage"><code>(ith-sum-sqr-err distfn Ci)</code></div><div class="doc"><pre class="plaintext">Sum of Squares Error for cluster Ci.  Ci is a map entry with key
the mean mi of Ci and val the points assigned to Ci.  distfn is the
distance function for the err (and must be the same as the distance
function assigning the points to Ci).
</pre></div></div><div class="public anchor" id="var-kmeans"><h3>kmeans</h3><div class="usage"><code>(kmeans initial-centers coll &amp; {:keys [distfn avgfn], :or {distfn vecdist, avgfn vecmean}})</code></div><div class="doc"><pre class="plaintext">Computes kmeans clustering over COLL starting with initial set of
centers INITIAL-CENTERS, using DISTFN as the distance function
between points and AVGFN as the &apos;means&apos; function for a cluster.

let k = count initial-centers
repeat
  form k clusters by grouping all p in coll with nearest center
  compute new k centers from clusters
until centers-i = centers-i+1

Return [Cs sse], where Cs is the set of clusters asssociated with
final centers and sse is the sum-sqr-err of Cs
</pre></div></div><div class="public anchor" id="var-kmeans.2B.2B"><h3>kmeans++</h3><div class="usage"><code>(kmeans++ k coll &amp; {:keys [distfn avgfn], :or {distfn vecdist, avgfn vecmean}})</code></div><div class="doc"><pre class="plaintext">kmeans++ clustering of COLL into K clusters.  Picks initial-centers
as (k++init k distfn coll) and then proceeds via kmeans.  As for
kmeans, DISTFN is the distance function between points and AVGFN is
the &apos;means&apos; function for a cluster.
</pre></div></div><div class="public anchor" id="var-knn"><h3>knn</h3><div class="usage"><code>(knn k distfn p coll)</code></div><div class="doc"><pre class="plaintext">Compute K nearest neighbors of point P in collection COLL.
Distance is given by means of distfn, preferably a metric, but can
be a &apos;similarity measure&apos; such as relative entropy.  O(nlogn)
complexity.
</pre></div></div><div class="public anchor" id="var-knn-graph"><h3>knn-graph</h3><div class="usage"><code>(knn-graph k distfn coll)</code></div><div class="doc"><pre class="plaintext">Compute the k nearest neighbors graph over the items in COLL as
determined by distance function distfn, preferably a metric, but
can be a &apos;similarity measure&apos; such as relative entropy.  Returns
the graph encoded as a map (sparse edge set matrix), with keys
items in COLL and values k-sets of items in COLL.
</pre></div></div><div class="public anchor" id="var-krnn-clust"><h3>krnn-clust</h3><div class="usage"><code>(krnn-clust k distfn coll &amp; {:keys [keyfn], :or {keyfn identity}})</code></div><div class="doc"><pre class="plaintext">
</pre></div></div><div class="public anchor" id="var-krnn-graph"><h3>krnn-graph</h3><div class="usage"><code>(krnn-graph knngraph coll)</code><code>(krnn-graph k distfn coll)</code></div><div class="doc"><pre class="plaintext">Compute the k reverse nearest neighbors graph over the items in
COLL as determined by the k nearest neighbors graph over COLL (see
knn-graph).  Distance of knn graph is determined by distance
function distfn, preferably a metric, but can be a &apos;similarity
measure&apos; such as relative entropy.

Alternately, the signature with KNNGRAPH, provides the k nearest
neighbor graph as a direct input.

Returns the graph encoded as a map (sparse edge set matrix), with
keys items in COLL and values sets of items in COLL.

NOTE: the size of the value sets for krnn need not be k, typically
isn&apos;t k, and can range from 0 to (count coll).
</pre></div></div><div class="public anchor" id="var-loyd-step"><h3>loyd-step</h3><div class="usage"><code>(loyd-step distfn avgfn data incenters)</code></div><div class="doc"><pre class="plaintext">Primary step in kmeans algorithm.  Recluster data to the &apos;new&apos;
centers incenters.  Take new clusters and compute and return newer
centers for all new clusters.  That&apos;s the basic Loyd step, but here
there is an extra wrinkle:

If (count new-clusters) is not equal (count incenters), some input
clusters have coalesced and need to be resplit (see
split-worst-cluster).  The result is then &apos;restepped&apos; until the
count of new clusters is count of incenters.
</pre></div></div><div class="public anchor" id="var-nearest"><h3>nearest</h3><div class="usage"><code>(nearest x distfn coll)</code></div><div class="doc"><pre class="plaintext">Return the nearest point p in coll to x.  Distance is given by
distfn.  If coll is a map uses (vals coll).
</pre></div></div><div class="public anchor" id="var-nearest-pd"><h3>nearest-pd</h3><div class="usage"><code>(nearest-pd x distfn coll)</code></div><div class="doc"><pre class="plaintext">Return the nearest point p in coll to x along with its distance.
Distance is given by distfn.  If coll is a map uses (vals coll).
Returns [p,d], where p is the nearest point and d its distance.
</pre></div></div><div class="public anchor" id="var-refoldin-outliers"><h3>refoldin-outliers</h3><div class="usage"><code>(refoldin-outliers krnngrph rnnG&gt;k-sccs rnnG&lt;k-sccs)</code><code>(refoldin-outliers krnngrph rnnG&gt;k-sccs rnnG&lt;k-sccs knngrph &amp; {:keys [minsize], :or {minsize 1}})</code></div><div class="doc"><pre class="plaintext">Takes a krnn graph and the SCC &apos;clusters&apos; corresponding to the s
</pre></div></div><div class="public anchor" id="var-S-Dbw-index"><h3>S-Dbw-index</h3><div class="usage"><code>(S-Dbw-index distfn clustering &amp; {:keys [avgfn], :or {avgfn mean}})</code></div><div class="doc"><pre class="plaintext">Compute the &apos;S_Dbw&apos; cluster validity index: Scatter plus Density
between.  By several accounts (IEEE 2010 ICDM paper &apos;Understanding
Internal Clustering Validity Measures&apos;, in particular) this is the
most robust general internal validity measure across both data sets
and clustering algorithms.  It is the default used by
FIND-CLUSTERS.

It accounts for both compactness of clusters and cluster
separation.  It does this with a dual density measure:

1. Scattering (see SCATT), which computes the average variance in
   clusters to the overall variance of the data set.

2. Intercluster density (so called &apos;Dens_bw&apos;, see
   INTERCLUSTER-DENSITY), which computes an averaged density in the
   space between all cluster pairs.

Note in particular that for convex sets, it is proved that the
clustering which minimizes Scatt + Dens_bw, is the optimal
clustering for the data set and algorithm pair (see Halkidi &amp;
Vazirgiannis, Clustering Validity Assesment: Finding Optimal
partitioning of a Data Set, Proc ICDM 2001, pp187-194).

DISTFN is the distance function for the data and AVGFN the &apos;mean&apos;
for the data.

Returns a floating point number as score.  The smaller the better.
</pre></div></div><div class="public anchor" id="var-scatt"><h3>scatt</h3><div class="usage"><code>(scatt distfn avgfn clustering)</code></div><div class="doc"><pre class="plaintext">Compute the compactness of a clustering by means of &apos;density&apos;
measure.  This is the averaged ratio of variance of clusters in
clustering to the overall variance of the data set:

let S all data points
    n (count clustering)
  (* 1/n (sum (fn[Ci] (/ (variance Ci) (variance S))) clustering))

Returns a floating point density score of compactness - the smaller
the better.
</pre></div></div><div class="public anchor" id="var-split-krnn"><h3>split-krnn</h3><div class="usage"><code>(split-krnn k krnngrph rnncntM knngrph)</code></div><div class="doc"><pre class="plaintext">Takes a krnn graph (as built by krnn-graph) for value k, with point
counts given by rnncntM (as built by krnn-graph) and the
corresponding knngrph that is the basis of the krnn graph, and
returns two new graphs [rnnG&gt;k rnnG&lt;k]:

rnnG&gt;k is the subgraph of krnngrph whose nodes have &gt;= k edges

rnnG&lt;k is the subgraph of krnngrph whose nodes have &lt; k edges

Additionally, all edge set nodes in both subgraphs that do not
appear as nodes in the subgraphs are removed (another choice would
have been to include them with null edge sets, but that would have
violated the constraints on rnnG&gt;k).

These two graphs form the basis for initial sets of clusters based
on the set of strongly connected components (SCC) in them.  These
SCC form the basis of both the Chameleon and RECORD clustering
algorithms.
</pre></div></div><div class="public anchor" id="var-split-worst-cluster"><h3>split-worst-cluster</h3><div class="usage"><code>(split-worst-cluster distfn avgfn clusters &amp; {:keys [wradius], :or {wradius 0.8}})</code></div><div class="doc"><pre class="plaintext">Clusters a cluster map as given by function CLUSTER (for which
see).  The functions distfn and avgfn are the distance and &apos;mean&apos;
functions used to build clusters.

Clusters is assumed to be smaller in count than it &apos;should&apos; be.
Using an error measure, which here is SSE (see ith-sum-sqr-err and
sum-sqr-err), clusters has a worst cluster Ci.  Split Ci by first
sorting its points by their distance from cmi, the center of Ci.
Then remove the points within WRADIUS percent of the furthest point
and place in new cluster wCi.  Remove Ci from clusters and add the
pair of clusters from splitting Ci:

new-clusters = clusters - Ci + (Ci - wCi) + wCi

Return new-clusters.
</pre></div></div><div class="public anchor" id="var-sum-sqr-err"><h3>sum-sqr-err</h3><div class="usage"><code>(sum-sqr-err distfn clusters)</code></div><div class="doc"><pre class="plaintext">Sum of Squares Error for a set of clusters (result of single loyd
step or end of k-means or ...).  distfn is the distance function
used to form the clusters (in a loyd step) and is also the distance
function for computing the errors.
</pre></div></div></div></body></html>